{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0660649fce63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0moperator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mattrgetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Log lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import calendar\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from operator import attrgetter\n",
    "\n",
    "from sklearn.metrics import precision_score, f1_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Log lib\n",
    "import logging\n",
    "from ast import literal_eval\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot lib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cufflinks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8e0bd7a1442c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Using plotly + cufflinks in offline mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcufflinks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mcufflinks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgo_offline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# cufflinks.go_offline()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cufflinks'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "\n",
    "# Standard plotly imports\n",
    "# import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "import plotly.express as px\n",
    "# Using plotly + cufflinks in offline mode\n",
    "import cufflinks\n",
    "cufflinks.go_offline(connected=True)\n",
    "# cufflinks.go_offline()\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path to data mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_common_directory = '/data/apps/jupyter_notebook/EDA/common_eda/input_common'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_common_directory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-94d79dd14541>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpath_north_province\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_common_directory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/3MienVN/mienbac.csv\"\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpath_central_province\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_common_directory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/3MienVN/mientrung.csv\"\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpath_south_province\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_common_directory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/3MienVN/miennam.csv\"\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpath_miennuibacbo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_common_directory\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0;34m\"/7vungkinhtevn/trungduvamiennuibacbo.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_common_directory' is not defined"
     ]
    }
   ],
   "source": [
    "path_north_province = input_common_directory + \"/3MienVN/mienbac.csv\";\n",
    "path_central_province = input_common_directory + \"/3MienVN/mientrung.csv\";\n",
    "path_south_province = input_common_directory + \"/3MienVN/miennam.csv\";\n",
    "\n",
    "path_miennuibacbo = input_common_directory +  \"/7vungkinhtevn/trungduvamiennuibacbo.csv\"\n",
    "path_dongbangsonghong =input_common_directory +  \"/7vungkinhtevn/dongbangsonghong.csv\"\n",
    "path_bactrungbo =input_common_directory +  \"/7vungkinhtevn/bactrungbo.csv\"\n",
    "path_namtrungbo =input_common_directory +  \"/7vungkinhtevn/namtrungbo.csv\"\n",
    "path_taynguyen =input_common_directory +  \"/7vungkinhtevn/taynguyen.csv\"\n",
    "path_dongnambo =input_common_directory +  \"/7vungkinhtevn/dongnambo.csv\"\n",
    "path_dongbangsongcuulong =input_common_directory +  \"/7vungkinhtevn/dongbangsongcuulong.csv\"\n",
    "\n",
    "path_mapping_telco = input_common_directory + \"/dausodt.csv\"\n",
    "path_mapping_career = input_common_directory + \"/career_mapping.csv\";\n",
    "path_location_mapping = input_common_directory + \"/outdata_norm_id_4_location_mapping.csv\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# auto eda lib (enable if need)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dataprep.eda import plot, plot_correlation, plot_missing\n",
    "# from pandas_profiling import ProfileReport\n",
    "# import sweetviz as sv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In Jupyter Notebooks, one clean way of solving this problem is using markdown:\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "pd.options.display.float_format = \"{:.4f}\".format\n",
    "pd.options.display.max_rows = 500\n",
    "pd.set_option('max_columns', 50)\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "\n",
    "from IPython.display import display_html\n",
    "def display_side_by_side(*args):\n",
    "    html_str=''\n",
    "    for df in args:\n",
    "        html_str+=df.to_html()\n",
    "    display_html(html_str.replace('table','table style=\"display:inline\"'),raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_explore_lite(input_dataframe):\n",
    "    \"\"\"\n",
    "        Show simple overral missing of dataframe columns\n",
    "        Args:\n",
    "            input_dataframe: pandas dataframe\n",
    "        Returns:\n",
    "            Table simple missing explore by columns (combine three columns: count_missing,count_total, percentile_missing)\n",
    "    \"\"\"\n",
    "    printmd(\"**Missing Explore**\")\n",
    "    naCount = input_dataframe.isnull().sum()\n",
    "    total = len(input_dataframe)\n",
    "    naPercent = (input_dataframe.isnull().sum()/len(input_dataframe)*100).round(2).map(lambda n: '{0:.1f} %'.format(n))\n",
    "    return pd.DataFrame({'count_missing': naCount, 'count_total': len(input_dataframe),'percentile_missing':naPercent})\n",
    "\n",
    "def missing_explore_full(input_dataframe):\n",
    "    \"\"\"\n",
    "        Show full overral missing of dataframe columns\n",
    "        Args:\n",
    "            input_dataframe: pandas dataframe\n",
    "        Returns:\n",
    "            Table full missing explore by columns (columns: count_total, count_unique, count_duplicate, count_zero, \n",
    "                                            percentile_zero, count_missing, percentile_missing, hit_rate)\n",
    "    \"\"\"\n",
    "    printmd(\"**Overral Stats**\")\n",
    "    total = len(input_dataframe)\n",
    "    naCount = input_dataframe.isnull().sum()\n",
    "    zeroCount = len(input_dataframe) - input_dataframe.fillna(1).astype(bool).sum()\n",
    "    zeroPercent = (zeroCount/len(input_dataframe)*100).round(2).map(lambda n: '{0:.2f} %'.format(n))\n",
    "    naPercent = (input_dataframe.isnull().sum()/len(input_dataframe)*100).round(2).map(lambda n: '{0:.2f} %'.format(n))\n",
    "    uniqCount = input_dataframe.nunique()\n",
    "    dupCount = []\n",
    "    for column_name in input_dataframe.columns:\n",
    "        dupCount.append(input_dataframe.duplicated(subset=column_name, keep='first').sum())\n",
    "    hitRate = (input_dataframe.notnull().sum()/len(input_dataframe)*100).round(2).map(lambda n: '{0:.2f} %'.format(n))\n",
    "    return pd.DataFrame({'count_total': total, 'count_unique': uniqCount, 'count_duplicate': dupCount, 'count_zero':zeroCount,'percentile_zero':zeroPercent, 'count_missing': naCount,'percentile_missing':naPercent, 'hit_rate':hitRate})\n",
    "\n",
    "def hit_rate_explore(df, column):\n",
    "    \"\"\"\n",
    "        Calculate percentage null and not null value of column in data frame\n",
    "        Args:\n",
    "            df: input dataframe\n",
    "            column: name of column need calculate hit rate\n",
    "        Returns:\n",
    "            hitrate table of column\n",
    "    \"\"\"\n",
    "    na_count = df[column].isnull().sum()\n",
    "    not_na_count = df[column].notnull().sum()\n",
    "    total = len(df)\n",
    "    na_percentage = '{0:.1f} %'.format(na_count/total*100)\n",
    "    not_na_percentage = '{0:.1f} %'.format(not_na_count/total*100)\n",
    "    return pd.DataFrame({'Category': ['Have ' + column, 'Does not have ' + column],\n",
    "                        'Count': [not_na_count, na_count],\n",
    "                        'Total': [total, total],\n",
    "                        'Percent': [not_na_percentage, na_percentage]})\n",
    "\n",
    "#Describe Data:\n",
    "def describe_numeric_data(column, round=2):\n",
    "    \"\"\"\n",
    "        Show describe numeric data\n",
    "        Args:\n",
    "            column: pandas serie datatype is numeric\n",
    "            round: round format number (default = 2)\n",
    "        Returns:\n",
    "            Table describe data (total, std, pecentiles,...)\n",
    "    \"\"\"\n",
    "    return column.describe(percentiles = [i*0.05 for i in range (20)] +[0.01] +[0.99]).round(round)\n",
    "\n",
    "def describe_category_data(column):\n",
    "    \"\"\"\n",
    "        Show describe category data\n",
    "        Args:\n",
    "            column: pandas serie datatype is category\n",
    "        Returns:\n",
    "            Table describe data (count values, percentiles)\n",
    "    \"\"\"\n",
    "    c = column.value_counts(dropna=False)\n",
    "    p = column.value_counts(dropna=False, normalize=True).map(lambda n: '{0:.2f} %'.format(n*100))\n",
    "    return pd.concat([c,p], axis=1, keys=['counts', 'percentiles(%)'])\n",
    "\n",
    "def describe_category_data_without_format(column):\n",
    "    \"\"\"\n",
    "        Show describe category data\n",
    "        Args:\n",
    "            column: pandas serie datatype is category\n",
    "        Returns:\n",
    "            Table describe data (count values, percentiles)\n",
    "    \"\"\"\n",
    "    c = column.value_counts(dropna=False)\n",
    "    p = column.value_counts(dropna=False, normalize=True)\n",
    "    return pd.concat([c,p], axis=1, keys=['counts', 'percentiles'])\n",
    "\n",
    "def descibe_2D_category_data(df_input, column1, column2):\n",
    "    \"\"\"\n",
    "        Show describe table 2 categories data\n",
    "        Args:\n",
    "            df_input: dataframe contain 2 categories column\n",
    "            column1: category column 1\n",
    "            column1: category column 2\n",
    "        Returns:\n",
    "            Table describe data (count values, percentiles)\n",
    "    \"\"\"\n",
    "    df_count = df_input.groupby([column1, column2])[column2].size().unstack(fill_value=0)\n",
    "    values = df_input[column2].dropna().unique()\n",
    "    df_percentile = pd.DataFrame()\n",
    "    for value in values:\n",
    "        df_percentile['percentile_' + str(value)] =  df_count[value]/df_count.sum(axis=1)\n",
    "        df_percentile['percentile_' + str(value)] = df_percentile['percentile_' + str(value)].apply(lambda x: \"{0:.2f} %\".format(x*100))\n",
    "    return df_count.join(df_percentile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print False Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_false_case(labels_list, df, pred_col_name, label_col_name):\n",
    "    \"\"\"\n",
    "    get the list of dataframe of false case\n",
    "    :return: list of dataframe\n",
    "    \"\"\"\n",
    "    false_df_list = []\n",
    "    for label in labels_list:\n",
    "        false_df = df[(df[pred_col_name] != df[label_col_name])&(df[label_col_name] == label)]\n",
    "        false_df_list.append(false_df)\n",
    "    return false_df_list\n",
    "\n",
    "def show_false_case(labels_list, df, pred_col_name, label_col_name, topn=5):\n",
    "    \"\"\"\n",
    "    show top false case of pandas serie\n",
    "    :return: list of false case\n",
    "    \"\"\"\n",
    "    dflist = get_false_case(labels_list, df, pred_col_name, label_col_name)\n",
    "    for dfitem, label in zip(dflist, labels_list):\n",
    "        if (label!= \"nan\") and (dfitem.shape[0] > 0):\n",
    "            print(color.BOLD + \"False of label '\" + str(label) + \"'\" + color.END)\n",
    "            display(dfitem[dfitem.columns.difference(['uid'])].head(topn))\n",
    "            print(\"===========================================================================================\")\n",
    "            print()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw Chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Private function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw Chart\n",
    "def _draw_bar_plotly_1D_with_orders(df_input, xTitle, labels = []):\n",
    "    '''\n",
    "        Private function draw bar chart for describe category column\n",
    "        Args: \n",
    "            df_input: dataframe groupby column need describe\n",
    "            xTitle: name of column need show in xTitle\n",
    "            labels: list category orders when plot chart \n",
    "        Returns:\n",
    "            Show bar chart for category column data\n",
    "    '''\n",
    "    n_cates = len(df_input)\n",
    "\n",
    "    width = 300 if (n_cates <= 2) else n_cates * max(50, 140 * np.power(0.92, n_cates / 2))\n",
    "    fig = px.bar(df_input,\n",
    "                 x=df_input.index,\n",
    "                 y='counts',\n",
    "                 text=df_input['percentiles(%)'],\n",
    "                 width=width,\n",
    "                 height=500,\n",
    "                 category_orders={column: labels})\n",
    "    fig.update_layout(transition_duration=500)\n",
    "    fig.update_layout(\n",
    "        title=title + \" Chart\",\n",
    "        xaxis_title=title,\n",
    "        yaxis_title=\"Counts\"\n",
    "    )\n",
    "    fig.update_layout(transition_duration=500)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_hist_plotly_1D(input_data, xTitle, title):\n",
    "    '''\n",
    "        Plotly draw histogram chart for continuous data\n",
    "        Args: \n",
    "            input_data: pandas serie continuous column need plot chart (example: df[column_name])\n",
    "            xTitle: title of xAxis (maybe column name)\n",
    "            title: title of Chart\n",
    "        Returns:\n",
    "            Show histogram chart for data\n",
    "    '''\n",
    "    input_data.astype(str).iplot(kind='hist', xTitle=xTitle, yTitle='count', title=title)\n",
    "    \n",
    "def draw_bar_plotly_1D(input_data):\n",
    "    '''\n",
    "        Plotly draw bar chart for category data\n",
    "        Args: \n",
    "            input_data: pandas serie category column need plot chart (example: df[column_name])\n",
    "        Returns:\n",
    "            Show histogram chart for data\n",
    "    '''\n",
    "    fig = px.bar(input_data.value_counts())\n",
    "    fig.show()\n",
    "\n",
    "def draw_pie_plt_1D(input_data):\n",
    "    \n",
    "    labels = input_data.value_counts(dropna=False).index\n",
    "    values = input_data.value_counts(dropna=False).values\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.pie(values, labels=labels, autopct='%1.1f%%',\n",
    "            shadow=True, startangle=90)\n",
    "    ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "    plt.show()\n",
    "\n",
    "def draw_pie_plotly_1D(input_data):\n",
    "    labels = input_data.value_counts(dropna=False).index\n",
    "    values = input_data.value_counts(dropna=False).values\n",
    "    fig = go.Figure(data=[go.Pie(labels=labels, values=values)])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Public function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_numeric_data_with_chart_hist(df_input, column_name, round=2):\n",
    "    \"\"\"\n",
    "        Describe data and plot histogram of numeric data\n",
    "        Arguments:\n",
    "            df_input: dataframe has column\n",
    "            column_name: name of column need describe\n",
    "            round: number of round data\n",
    "    \"\"\"\n",
    "    print(color.BOLD + \"Describe data of \" + column_name + \":\" + color.END)\n",
    "    display(describe_numeric_data(df_input[column_name], round))\n",
    "    print(color.BOLD + \"Historam chart of \" + column_name + \":\" + color.END)\n",
    "    if len(df_input) > 100000:\n",
    "        draw_hist_plotly_1D_matplotlib(df_input[column_name], column_name, \"Chart count of \" + column_name)\n",
    "    else:\n",
    "        draw_hist_plotly_1D(df_input[column_name], column_name, \"Chart count of \" + column_name)\n",
    "    \n",
    "def describe_category_data_with_chart_bar(df_input, column_name, labels = []):\n",
    "    \"\"\"\n",
    "        Describe data and plot bar chart of category data\n",
    "        Arguments:\n",
    "            df_input: dataframe has column\n",
    "            column_name: name of column need describe\n",
    "            labels: list sort labels when plot (default empty array will sort by count value decreasing)\n",
    "    \"\"\"\n",
    "    column = df_input[column_name]\n",
    "    dfg = describe_category_data(column)\n",
    "    print(color.BOLD + \"Describe data of \" + column_name + \":\" + color.END)\n",
    "    display(dfg)\n",
    "    print(color.BOLD + \"Historam chart of \" + column_name + \":\" + color.END)\n",
    "    if len(labels) == 0:\n",
    "        if not np.issubdtype(df_input[column_name].dtype, np.number) and not column_name == 'age_group':\n",
    "            labels = df_input[column_name].value_counts().index\n",
    "        else:\n",
    "            labels = df_input[column_name].dropna().unique()\n",
    "            labels.sort()\n",
    "#     if len(df_input) > 100000: # Plotly xài groupby rồi nên rất nhẹ\n",
    "#         draw_bar_matplotlib_1D_with_orders(df_input, column_name, labels)\n",
    "#     else:\n",
    "    _draw_bar_plotly_1D_with_orders(dfg, column_name, \"Distributed of \" + column_name, labels)\n",
    "    \n",
    "def describe_category_data_with_chart_pie(column, column_name):\n",
    "    \"\"\"\n",
    "        Describe data and plot bar chart of category data\n",
    "        Arguments:\n",
    "            df_input: dataframe has column\n",
    "            column_name: name of column need describe\n",
    "            labels: list sort labels when plot (default empty array)\n",
    "    \"\"\"\n",
    "    print(color.BOLD + \"Describe data of \" + column_name + \":\" + color.END)\n",
    "    display(describe_category_data(column))\n",
    "    print(color.BOLD + column_name + \" distribution:\" + color.END)\n",
    "    draw_pie_plotly_1D(column)\n",
    "\n",
    "def describe_category_with_draw_hist_plotly_2D(df_input, column1, column2):\n",
    "    \"\"\"\n",
    "        Describe 2D data and plot histogram chart of category data\n",
    "        Arguments:\n",
    "            df_input: dataframe has column\n",
    "            column1: name of category column 1\n",
    "            column2: name of category column 2\n",
    "    \"\"\"\n",
    "    print(color.BOLD + \"Describe data of \" + column1 + \" and \" + column2 +\":\" + color.END)\n",
    "    display(descibe_2D_category_data(df_input, column1, column2))\n",
    "    print(color.BOLD + \"Data distribution:\" + color.END)\n",
    "    draw_hist_plotly_2D(df_input, column1, column2)\n",
    "    \n",
    "def draw_line_time_series_chart_plotly_1D(df_input, column):\n",
    "    \"\"\"\n",
    "        Plot time series data to chart line\n",
    "        Arguments:\n",
    "            df_input: data frame has column need plot\n",
    "            column: name of time series column\n",
    "    \"\"\"\n",
    "    column_datetime_format = df_input[column].dt.strftime('%Y/%m')\n",
    "    time_series = pd.DataFrame(column_datetime_format.value_counts().reset_index())\n",
    "    time_series.columns = ['date', 'count']\n",
    "    time_series = time_series.sort_values('date', ascending=True)\n",
    "    fig = px.line(time_series, x=\"date\", y=\"count\", title='Count by ' + column)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def draw_line_ploty_mean_2D(df_input, column1, column2):\n",
    "    df_input = df_input.groupby([column1], as_index=False).mean()\n",
    "    fig = px.line(df_input, x=column1, y=column2, title=''.join([column1,' + ',column2]))\n",
    "    fig.show()\n",
    "    \n",
    "def draw_line_ploty_2D_with_filter_na(df_input, column1, column2):\n",
    "    df_input = df_input[(df_input[column1].notnull()) & (df_input[column1] > 0) & (df_input[column2].notnull())][[column1, column2]]\n",
    "    draw_line_ploty_2D(df_input, column1, column2)\n",
    "    \n",
    "def draw_hist_plotly_2D(df_input, x_axis, color):\n",
    "    fig = px.histogram(df_input, x=x_axis, color=color,\n",
    "                   barmode='relative',\n",
    "                   hover_data=df_input.columns)\n",
    "    fig.show()\n",
    "    \n",
    "def draw_bar_plotly_2D(df_input, x_axis, color):\n",
    "    fig = px.bar(df_input, x=x_axis, color=color,\n",
    "                   barmode='relative',\n",
    "                   hover_data=df_input.columns)\n",
    "    fig.show()\n",
    "    \n",
    "def draw_cate_and_cate_chart_nested_bar_count_plotly_2D(df_input, columnX, columnY):\n",
    "    inputdf = df_input[(df_input[columnX].notnull()) & (df_input[columnY].notnull())]\n",
    "    fig = px.histogram(inputdf, x=columnX, y=columnY, color=columnY, histfunc=\"count\", barmode=\"group\")\n",
    "    fig.show()\n",
    "\n",
    "def draw_cate_and_cate_chart_stacked_bar_percent_plotly_2D(df_input, columnX, columnY):\n",
    "    inputdf = df_input[(df_input[columnX].notnull()) & (df_input[columnY].notnull())]\n",
    "    fig = px.histogram(inputdf, x=columnX, y=columnY, color=columnY, histfunc=\"count\", barmode=\"relative\", barnorm='percent')\n",
    "    fig.show()\n",
    "    \n",
    "def describe_2D_fullflow(df_input, column1, column2, labels_list, figsize):\n",
    "#     df_without_invalid_uid = df_input[df_input.uid.notnull()]\n",
    "#     print(plot_confusion_matrix(df_input[column1].astype(str), df_input[column2].astype(str), figsize=figsize, title=\"Confusion Matrix With Full Data\"))\n",
    "#     print(plot_confusion_matrix(df_without_invalid_uid[column1].astype(str), df_without_invalid_uid[column2].astype(str), figsize=figsize, title=\"Confusion Matrix Without Invalid Uid Data\"))\n",
    "    df_input_notnull=df_input[df_input[column1].notnull() & df_input[column2].notnull()]\n",
    "    print(plot_confusion_matrix(df_input_notnull[column1].astype(str), df_input_notnull[column2].astype(str), figsize=figsize, title=\"Confusion Matrix Without Nan Data\"))\n",
    "    # show false case\n",
    "    unique_labels_list = df_input[df_input[column1].notnull()][column1].unique()\n",
    "    show_false_case(unique_labels_list, df_input, column1, column2, topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_hist_plotly_1D_matplotlib(x, xTitle, title):\n",
    "    '''Plot Historgram using matplotlib'''\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.hist(x, bins=30, label=title)\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel(xTitle)\n",
    "    plt.title(\"Histogram Count\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.hist(x, bins=30, density=True)\n",
    "    sns.kdeplot(x);\n",
    "    plt.ylabel('Probability')\n",
    "    plt.xlabel(xTitle)\n",
    "    plt.title(\"Histogram Probability\")\n",
    "    plt.show()\n",
    "    \n",
    "def draw_bar_matplotlib_1D_with_orders(df_input, column_name, order_labels):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.set(style='darkgrid')\n",
    "    ax = sns.countplot(x=column_name, data=df_input, order = order_labels)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def draw_box_seaborn_2D(df_input, x, y):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    ax = sns.boxplot(data=df_input, x=x, y=y)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def draw_cate_and_cate_chart_nested_bar_count_seaborn_2D(df_input, x, hue):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.set(style='darkgrid')\n",
    "    ax = sns.countplot(x=x,hue=hue,data=df_input)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_months(sourcedate, n_months):\n",
    "    '''\n",
    "        Add n_months month to sourcedate\n",
    "        Args:\n",
    "            sourcedate (datetime): input date need add months\n",
    "            n_months: number of months need add\n",
    "        Returns: \n",
    "            datetime result after add n_months\n",
    "    '''\n",
    "    month = sourcedate.month - 1 + months\n",
    "    year = sourcedate.year + month // 12\n",
    "    month = month % 12 + 1\n",
    "    day = min(sourcedate.day, calendar.monthrange(year,month)[1])\n",
    "    return datetime(year, month, day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unicode(data):\n",
    "    \"\"\"\n",
    "    Remove unicode characters from string using lib unidecode\n",
    "        Args:\n",
    "            data: Input string\n",
    "        \n",
    "        Returns:\n",
    "            decode_data: string removed unicode characters\n",
    "            \n",
    "    \"\"\"\n",
    "    return unidecode.unidecode(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_gender(gender):\n",
    "    '''\n",
    "        Format gender \n",
    "    '''\n",
    "    if gender == 1:\n",
    "        return \"Male\"\n",
    "    elif gender == 2:\n",
    "        return \"Female\"\n",
    "    return np.nan\n",
    "\n",
    "def parentalstatus_mapping(parentalstatus):\n",
    "    if parentalstatus == 'NOT_A_PARENT':\n",
    "        return 'Not_a_parent'\n",
    "    elif parentalstatus == 'PARENT':\n",
    "        return 'Parent'\n",
    "    return np.nan\n",
    "\n",
    "def maritalstatus_mapping(status):\n",
    "    if status == 0:\n",
    "        return 'Unknown'\n",
    "    elif status == 1:\n",
    "        return 'Married'\n",
    "    return np.nan\n",
    "\n",
    "#Name\n",
    "def getNameFromFullName(fullname):\n",
    "    arr_name = fullname.split()\n",
    "    return arr_name[len(arr_name) - 1].capitalize()\n",
    "\n",
    "#Age\n",
    "def getAgeFromDOB(dob):\n",
    "    \n",
    "    arr_dob = dob.split(\"/\")\n",
    "    now = datetime.now()\n",
    "    return now.year - int(arr_dob[len(arr_dob) - 1])\n",
    "\n",
    "def delta_age(age1, age2):\n",
    "    \"\"\"\n",
    "        Calculate delta between two age data\n",
    "        Arguments: \n",
    "            age1: predited age\n",
    "            age2: actual age\n",
    "        Returns:\n",
    "            delta_age\n",
    "    \"\"\"\n",
    "    if(abs(age1 - age2) > 5):\n",
    "        return '>5'\n",
    "    return '=' + str(abs(age1 - age2))\n",
    "\n",
    "def format_limit_data_with_top_number_value(df_input, column_name, ntop=10, other_name=\"Others\"):\n",
    "    \"\"\"\n",
    "        Format category data to top data and others value\n",
    "        Arguments: \n",
    "            df_input: dataframe input\n",
    "            column_name: name of columns need to format\n",
    "            ntop: number of top value \n",
    "            other_name: name of other value\n",
    "    \"\"\"\n",
    "    df_counts = df_input[column_name].value_counts().sort_values(ascending=False).rename_axis('name').reset_index(name='count')\n",
    "    serie_column = df_input[column_name].copy()\n",
    "    list_top_data = df_counts.head(n=ntop)['name'].tolist()\n",
    "    serie_column.loc[~serie_column.isin(list_top_data) & serie_column.notnull()] = other_name\n",
    "    df_input[column_name + '_limit'] = serie_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove invalid format data row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_format_some_feature_internal(df):\n",
    "    '''\n",
    "        Format some feature internal if feature is in dataframe \n",
    "        List features support ('agev2_predicted', 'genderv2_predicted', 'maritalstatus_predicted', \n",
    "                                'parentalstatus_predicted', 'home_predicted', 'work_predicted', 'livingprovince_predicted')\n",
    "        Args:\n",
    "            df: dataframe input need format\n",
    "        Returns:\n",
    "            dataframe with list features was formatted\n",
    "    '''\n",
    "    \n",
    "    if 'agev2_predicted' in df.columns:\n",
    "        df['agev2_predicted'] = df[df['agev2_predicted'].notnull()]['agev2_predicted'].astype(int)\n",
    "    if 'genderv2_predicted' in df.columns:\n",
    "        df['genderv2_predicted'] = df[df['genderv2_predicted'].notnull()]['genderv2_predicted'].astype(int).apply(format_gender)\n",
    "    if 'maritalstatus_predicted' in df.columns:\n",
    "        df['maritalstatus_predicted'] = df['maritalstatus_predicted'].apply(maritalstatus_mapping)\n",
    "    if 'parentalstatus_predicted' in df.columns:\n",
    "        df['parentalstatus_predicted'] = df['parentalstatus_predicted'].apply(parentalstatus_mapping)\n",
    "    if 'home_predicted' in df.columns:\n",
    "        df['home_predicted'] = df['home_predicted'].apply(lambda x: f'{x:.0f}').astype(str)\n",
    "    if 'work_predicted' in df.columns:\n",
    "        df['work_predicted'] = df['work_predicted'].apply(lambda x: f'{x:.0f}').astype(str)\n",
    "    if 'livingprovince_predicted' in df.columns:\n",
    "        df['livingprovince_predicted'] = df['livingprovince_predicted'].apply(lambda pr: pr.replace('Thành phố ', '').replace('Tỉnh ', '') if isinstance(pr, str) else np.nan)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Dic Career"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Clean Input Data\n",
    "with open(path_mapping_career) as f:\n",
    "    fileobject = io.StringIO(f.read().replace(\",'\",\"\").replace(\"'\",\"\"))\n",
    "# Read Map Career \n",
    "dic_career = pd.read_csv(fileobject, sep='\\t', header=None, index_col=0, squeeze=True).to_dict()\n",
    "# Extract out keys and values\n",
    "k_car = np.array(list(dic_career.keys()))\n",
    "v_car = np.array(list(dic_career.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Dic Province"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Map Career \n",
    "df_location = pd.read_csv(path_location_mapping, sep='\\t', header=None, squeeze=True)\n",
    "df_location[6] = df_location[6].astype(str).apply(lambda loc: ''.join(['241', loc.zfill(6)]))\n",
    "dic_location = df_location.set_index(6)[7].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Data\n",
    "def replace_with_dict_location(province_id):\n",
    "    try:\n",
    "        if province_id:\n",
    "            return dic_location[province_id]\n",
    "        else:\n",
    "            return np.nan\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Category with Top data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_format_mapping_location(df):\n",
    "    list_mapping_location = ['home_predicted', 'work_predicted']\n",
    "    for column in list_mapping_location:\n",
    "        if column in df.columns:\n",
    "            df[column + '_province'] = df[df[column].notnull()][column].apply(replace_with_dict_location)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_format_top_data(df, ntop = 10):\n",
    "    \"\"\"\n",
    "        Format all category features if exist in dataframe to list top data and others \n",
    "        ('occupationFirst_predicted','livingprovince_predicted', 'home_predicted_province', 'work_predicted_province', 'hometown_predicted')\n",
    "        Arguments: \n",
    "            df: data frame need format\n",
    "            ntop: number of top data (others will be assign for other datas)\n",
    "        Returns:\n",
    "            df: data frame contain format data\n",
    "    \"\"\"\n",
    "    list_get_top_data = ['occupationFirst_predicted','livingprovince_predicted', 'home_predicted_province', 'work_predicted_province', 'hometown_predicted']\n",
    "\n",
    "    for column in list_get_top_data:\n",
    "        if column in df.columns:\n",
    "            format_limit_data_with_top_number_value(df, column, ntop, \"Others\")\n",
    "    return df \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function mapping-convert data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Private function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_phone_start_of_raw_phone(phone):\n",
    "    try:\n",
    "        if phone:\n",
    "            phone = str(phone)\n",
    "            if len(phone) < 9 or len(phone) >=12:\n",
    "                return ''\n",
    "            if len(phone) >= 11 and phone[:2] == '84':\n",
    "                phone = phone[2:]\n",
    "            elif phone[:1] == '0':\n",
    "                phone = phone[1:]\n",
    "            return phone[:2]\n",
    "    except:            \n",
    "        return ''\n",
    "    return ''\n",
    "\n",
    "def _group_age_apply_func(age):\n",
    "    if np.isnan(age) or age is None or age <= 0:\n",
    "        return np.nan\n",
    "    elif age <= 17:\n",
    "        return \"17 Trở xuống\"\n",
    "    elif age <= 24:\n",
    "        return \"18-24\"\n",
    "    elif age <= 34:\n",
    "        return \"25-34\"\n",
    "    elif age <= 44:\n",
    "        return \"35-44\"\n",
    "    elif age <= 59:\n",
    "        return \"45-59\"\n",
    "    return \"60 Trở lên\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Public function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_age_mapping(df_input, age_column_name):\n",
    "    '''\n",
    "        Get group age from age column\n",
    "        Arg:\n",
    "            df_input: dataframe contain age column\n",
    "            age_column_name: age column name in dataframe\n",
    "        Return:\n",
    "            pandas series group age combine list group(\"17 Trở xuống\", \"18-24\", \"25-34\", \"35-44\", \"45-59\", \"60 Trở lên\")\n",
    "    '''\n",
    "    return df[age_column_name].apply(_group_age_apply_func)\n",
    "\n",
    "def gender_mapping(gender):\n",
    "    if gender == 1:\n",
    "        return 'Nam'\n",
    "    elif gender == 2:\n",
    "        return 'Nữ'\n",
    "    return np.nan\n",
    "\n",
    "def telco_mapping(df_input, phone_column_name, type_phone = 'raw'):\n",
    "    '''\n",
    "        Get telco name from phone column\n",
    "        Arg:\n",
    "            df_input: dataframe contain phone column\n",
    "            phone_column_name: phone column name in dataframe\n",
    "            type_phone: 'raw' or 'noise'\n",
    "        Return:\n",
    "            pandas series telco name\n",
    "    '''\n",
    "    df_telco = pd.read_csv(path_mapping_telco, sep=',', header=None, squeeze=True)\n",
    "    df_telco.columns= [\"phone_start\", \"telco_name\", \"noise_phone_start\"]\n",
    "    df_input_merge = df_input[[phone_column_name]].dropna().drop_duplicates()\n",
    "    if type_phone == 'noise':\n",
    "        df_telco[\"phone_start_formatted\"] = df_telco[\"noise_phone_start\"].astype(str)\n",
    "        df_input_merge[\"phone_start_formatted\"] = df_input_merge[phone_column_name].astype(str).str[0:7]\n",
    "    else:\n",
    "        df_telco[\"phone_start_formatted\"] = df_telco[\"phone_start\"].astype(str)\n",
    "        df_input_merge[\"phone_start_formatted\"] = df_input[phone_column_name].apply(_get_phone_start_of_raw_phone)\n",
    "    df_input_merge = pd.merge(left=df_input_merge, right=df_telco[[\"phone_start_formatted\", \"telco_name\"]], how='left', on='phone_start_formatted')\n",
    "    display(df_input_merge)\n",
    "    return pd.merge(left=df_input, right=df_input_merge[[phone_column_name, \"telco_name\"]], how='left', on=phone_column_name)[\"telco_name\"]\n",
    "\n",
    "def format_province_by_3zone(serie_province): \n",
    "    df_north_province = pd.read_csv(path_north_province, sep='\\t', header=None, squeeze=True)\n",
    "    df_central_province = pd.read_csv(path_central_province, sep='\\t', header=None, squeeze=True)\n",
    "    df_south_province = pd.read_csv(path_south_province, sep='\\t', header=None, squeeze=True)\n",
    "    serie_province.loc[serie_province.isin(df_north_province.tolist())] = 'Các tỉnh miền Bắc'\n",
    "    serie_province.loc[serie_province.isin(df_central_province.tolist())] = 'Các tỉnh miền Trung'\n",
    "    serie_province.loc[serie_province.isin(df_south_province.tolist())] = 'Các tỉnh miền Nam'\n",
    "    return serie_province\n",
    "\n",
    "def format_province_by_5zone(serie_province): \n",
    "    whitelist = [\"Hồ Chí Minh\", \"Hà Nội\"]\n",
    "    df_north_province = pd.read_csv(path_north_province, sep='\\t', header=None, squeeze=True)\n",
    "    df_central_province = pd.read_csv(path_central_province, sep='\\t', header=None, squeeze=True)\n",
    "    df_south_province = pd.read_csv(path_south_province, sep='\\t', header=None, squeeze=True)\n",
    "    serie_province.loc[(serie_province.isin(df_north_province.tolist())) & (~serie_province.isin(whitelist))] = 'Các tỉnh miền Bắc'\n",
    "    serie_province.loc[(serie_province.isin(df_central_province.tolist())) & (~serie_province.isin(whitelist))] = 'Các tỉnh miền Trung'\n",
    "    serie_province.loc[(serie_province.isin(df_south_province.tolist())) & (~serie_province.isin(whitelist))] = 'Các tỉnh miền Nam'\n",
    "    return serie_province\n",
    "    \n",
    "def format_province_by_7zone(serie_province): \n",
    "    df_path_miennuibacbo = pd.read_csv(path_miennuibacbo, sep='\\t', header=None, squeeze=True)\n",
    "    df_path_dongbangsonghong = pd.read_csv(path_dongbangsonghong, sep='\\t', header=None, squeeze=True)\n",
    "    df_path_bactrungbo = pd.read_csv(path_bactrungbo, sep='\\t', header=None, squeeze=True)\n",
    "    df_path_namtrungbo = pd.read_csv(path_namtrungbo, sep='\\t', header=None, squeeze=True)\n",
    "    df_path_taynguyen = pd.read_csv(path_taynguyen, sep='\\t', header=None, squeeze=True)\n",
    "    df_path_dongnambo = pd.read_csv(path_dongnambo, sep='\\t', header=None, squeeze=True)\n",
    "    df_path_dongbangsongcuulong = pd.read_csv(path_dongbangsongcuulong, sep='\\t', header=None, squeeze=True)\n",
    "    serie_province.loc[serie_province.isin(df_path_miennuibacbo.tolist())] = 'Trung du và miền núi Bắc bộ'\n",
    "    serie_province.loc[serie_province.isin(df_path_dongbangsonghong.tolist())] = 'Đồng bằng sông Hồng'\n",
    "    serie_province.loc[serie_province.isin(df_path_bactrungbo.tolist())] = 'Bắc Trung bộ'\n",
    "    serie_province.loc[serie_province.isin(df_path_namtrungbo.tolist())] = 'Nam Trung bộ'\n",
    "    serie_province.loc[serie_province.isin(df_path_taynguyen.tolist())] = 'Tây Nguyên'\n",
    "    serie_province.loc[serie_province.isin(df_path_dongnambo.tolist())] = 'Đông Nam bộ'\n",
    "    serie_province.loc[serie_province.isin(df_path_dongbangsongcuulong.tolist())] = 'Đồng bằng sông Cửu Long'\n",
    "    return serie_province"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "279.422px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
